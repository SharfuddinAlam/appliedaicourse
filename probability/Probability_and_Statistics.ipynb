{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability & Statistics \n",
    "\n",
    "Lets say we have a classification problem with three classes C1, C2 and C3, we fit a machine learning model M to the train data set. From the test data set we pick up a query point and pass it through model M. Using probability theory, we can get class probabilites for the query point,  having class probabilites is intutitive and interpretable. \n",
    "\n",
    "### Random Variable ($X$)\n",
    "$X$ is said to be random variable if the value of $X$ is a function whose domain is same as the probability experiment with finite (countably infinte) outcomes\n",
    "\n",
    "Example: let our proability experiment be roll of fair die. The sample space is {1,2,3,4,5,6}. Random variable $X$ will be {1,2,3,4,5,6} any value less than 1 or greater than 6 cannot be part of set $X$. \n",
    "\n",
    "Example: let our proability experiment be toss of fair coin. The sample space is {H,T}. Random variable $X$ will be {H,T} any value other than H or T, cannot be part of set $X$. \n",
    "\n",
    "This $P(X=x_i)$ = $P(x_i)$ means, the probabilty of random variable $X$ taking $x_i$ value is .. \n",
    "\n",
    "Example: What is the probability of the outcome from a roll of a fair die is odd? \n",
    "\n",
    "The sample space of the experiment is $S = \\{1,2,3,4,5,6\\}$\n",
    "\n",
    "\\begin{align}\n",
    "P(X=odd) & = P(X=1)+P(X=3)+P(X=5) \\\\\n",
    "P(X=odd) & = 1/6 +1/6 +1/6 \\\\\n",
    "P(X=odd) & = 1/2\n",
    "\\end{align}\n",
    "\n",
    "There are two types of random variables discrete and continuous. \n",
    "* Discrete - roll of a dice, coin flip. \n",
    "* Continuous - heigth of a person, any real value\n",
    "\n",
    "### Conditional Probability \n",
    "\n",
    "Let A and B be two random variables, the probability of an event A to happen conditioned (by assumption, presumption, assertion or evidence)) that B has already happened is called conditional probability $P(A|B) = \\frac {P(A \\cap B)} {P(B)} $\n",
    "\n",
    "Example: Let D1 be outcome of a fair die d1 and D2 be the outcome of a fair die d2, what is the probability that D1 = 2 given that D1 + D2 ≤ 5\n",
    "\n",
    "The conditioned event B is $D1 + D2 \\le 5 $ and the event A is D1=2,so $P(A \\cap B) = \\frac 3 {36} $ and $P(B) = \\frac {10} {36} $\n",
    "![scatter_plot_iris](../images/con_prob.png)\n",
    "\n",
    "\n",
    "**Independent Event**\n",
    "\n",
    "If the occurrence of one event does not influence or is not influenced by the occurrence of the other events. Two events are independent if $P(A|B) =P(A)$ or $P(B|A)=P(B)$, this means $P(A)$ is not dependent on $P(B)$\n",
    "\n",
    "**Mutually Exclusive Events**\n",
    "\n",
    "Two events cannot happen/occur at the same time, example when you flip a coin we get either head or tail not both $P(A|B)=P(B|A)=0$ or $P(A \\cap B) =0$\n",
    "\n",
    "* Multiplication Rule\n",
    "\n",
    "The probability that both events can occur $P(A \\cap B) = P(A|B)P(B) = P(B|A)P(A)$\n",
    "\n",
    "Extended MR rule for more than three events to occur at the same time $P(A \\cap B \\cap C) =  P(C| A \\cap B) P(B|A)P(A)$\n",
    "\n",
    "\n",
    "### Bayes Theorem \n",
    "\n",
    "$$ P(A|B) = \\frac {P(B|A) P(A)} {P(B)}$$\n",
    "\n",
    "$P(A|B)$: probability of event A given B occured \n",
    "\n",
    "$P(B|A)$: probability of event B given A occured \n",
    "\n",
    "$P(A)$  : probability of event A\n",
    "\n",
    "$P(B)$  : probability of event B\n",
    "\n",
    "\n",
    "Example: Lets say drone is manufactured from three factories A, B and C. If a randomly selected drone is defective (D),  what is the probability that the drone is from factory C. We given total percentage production from each factory i.e. P(A), P(B) and P(C). We are also given, the proability of defective peices from each factory i.e. P(D|A), P(D|B), P(D|C). \n",
    "\n",
    "We want $P(C|D)$:\n",
    "\n",
    "From CP we $P(C|D) = \\frac {P(C \\cap D)} {P(D)}$\n",
    "\n",
    "From MR we can rewrite $P(C \\cap D) = P(D|C)P(C)$\n",
    "\n",
    "What is $P(D)$ this our drone can be defective in one of three ways i.e. could be defective from A or B or C (all mutually exclusive events) $P(D) = P(D \\cap A) \\cup P(D \\cap B) \\cup P(D \\cap C)$, since mutually exclusive we ca n add them together $P(D) = P(D \\cap A) + P(D \\cap B) + P(D \\cap C)$\n",
    "\n",
    "Using MR $P(D \\cap A) = P(D|A)P(A) $,$P(D \\cap B) = P(D|B)P(B) $,$P(D \\cap C) = P(D|C)P(C)$\n",
    "\n",
    "\n",
    "Finally $P(C|D) = \\frac {P(D|C)P(C)} {P(D|A)P(A)P(D|B)P(B)P(D|C)P(C)}$\n",
    "\n",
    "\n",
    "### Guassian/Normal Probability Distribution\n",
    "* Often used in natural (height and weight of people, flower sizes etc) and social sciences, this distribution is useful in representing random variable whose distributions are not known. \n",
    "* This distribution has this form $X$= $N(\\mu,\\sigma^2)$, where $\\mu$ is mean and $\\sigma^2$ is variance\n",
    "\n",
    "Formula\n",
    "$$P(X=x)=\\frac{1}{ \\sqrt{2\\pi\\sigma^2}} e^{\\left(-\\frac{{\\left(x - \\mu\\right)}^{2}}{2 \\, \\sigma^{2}}\\right)} $$\n",
    "\n",
    "let $\\mu=0$ and $\\sigma^2=1$, then \n",
    "\n",
    "$$P(X=x)=\\frac{1}{ \\sqrt{2\\pi}} e^{-\\frac {x^2} {2}}$$\n",
    "\n",
    "ignoring the constants $\\frac{1}{ \\sqrt{2\\pi}}$ and $\\frac{1} {2}$, then $P(X) \\sim e^{-x^2} $, plot of  $e^{-x^2}$ show below\n",
    "\n",
    "![scatter_plot_iris](../images/ndist.png)\n",
    "\n",
    "As $x$ moves aways from $\\mu$ the probability reduces exponentially\n",
    "\n",
    "**CDF of Gaussian Distribution**\n",
    "* CDF can help us in determinig if the probability of a random value from the population will be greater than certain value or between two values \n",
    "* CDF is useful in calculating the p-value, p-value = 1 - CDF\n",
    "* Lets say we have a water bottle company, we produce 2 liter bottles. if we pick one bottle at random, using CDF we can tell if the fill weight ( 2 lit ~ 4.4 pounds) is less than 4 pounds or between certain value or greater than certain value. \n",
    "* \n",
    "![scatter_plot_iris](../images/cdf_normal.png)\n",
    "\n",
    "**68-95-99 Rule**\n",
    "\n",
    "* 50% points are on either side of the mean\n",
    "* 68% points are in range $[\\mu+\\sigma, \\mu -\\sigma]$\n",
    "* 95% points are in range $[\\mu+2\\sigma, \\mu -2\\sigma]$\n",
    "* 99% points are in range $[\\mu+3\\sigma, \\mu -3\\sigma]$\n",
    "* Very useful in creating control charts and detecting outliers \n",
    "![scatter_plot_iris](../images/68_95_99.png)\n",
    "\n",
    "**Skewness**\n",
    "\n",
    "* measure of the asymmetry of the probability distribution of a real-valued random variable about its mean.\n",
    "![scatter_plot_iris](../images/skew.jpeg)\n",
    "\n",
    "**Kurtosis**\n",
    "* measure of peakedness or how sharp the bell of the curve is\n",
    "* Each histogram has a unique Kurtosis value \n",
    "![scatter_plot_iris](../images/kurtosis.png)\n",
    "\n",
    "**Standard Normal Variate**\n",
    "\n",
    "* Random variable with $\\mu=0$ and standard deviation=1\n",
    "* Column standardization - convert any normal distribution to standard normal variate $\t\\forall x $ in a given column subtract $\\frac {x_i-\\mu}{\\sigma}$\n",
    "* Useful to control the scale or the variability of the dataset\n",
    "* non standardized values in a column can affect clustering algos \n",
    "* if features with small values contribute to class seperability then feature with a larger value will overshadow the effects of the feature with a smaller value leading to incorrect predictions\n",
    "\n",
    "**Kernel Density Estimation**\n",
    "* Convert histogram to density curve\n",
    "\n",
    "\n",
    "### Sampling Distribution & Central Limit Theorm \n",
    "\n",
    "* Let $X$ be a random variable from any distribution has a finite $\\mu$ and $\\sigma^2$, then if you collect enough samples from that unknown or known distribution then the mean of the sampling distribution will be a normal gaussian distribution. \n",
    "![scatter_plot_iris](../images/clt.png)\n",
    "\n",
    "* Rule of thumb the number of samples you should collect should be ~ 30 \n",
    "* Applications\n",
    "    * we can use the mean of sampling distribution to create confidence intervals\n",
    "    * useful in T-tests (difference between two sample means)\n",
    "    * useful in ANOVA (difference between more than two sample means)\n",
    "    * Can be used in noise cancellation \n",
    "    * The probability distribution for total distance covered in a random walk (biased or unbiased) will tend toward a normal distribution.\n",
    "\n",
    "### Q-Q Plot\n",
    "\n",
    "Used for testing if the random variable is normally distributed or not\n",
    "\n",
    "Example: Given a random variable $X$ : ${x_1, x_2,x_3,...x_n}$ is $X$ normally distributed or not?\n",
    "\n",
    "Step1: Sort $x_i$ asc order\n",
    "\n",
    "Step2: Compute percentiles, let ${x}^{1}, {x}^{2}, ..., {x}^{n}$ be the corresponding percentiles. \n",
    "\n",
    "Step3: Create a RV $Y$:${y_1, y_2,y_3,...y_n}$, a standard distribution with $\\mu$=0 and $\\sigma^2$=1, $N(0,1)$. \n",
    "\n",
    "Step4: Sort all $y_i$ in asc order and compute percentiles, let  ${y}^{1}, {y}^{2}, ..., {y}^{n}$ be the corresponding percentiles.\n",
    "\n",
    "Step5: Scatter plot (Q-Q plot) using $({x}^{1}, {y}^{1}),({x}^{2}, {y}^{2}),({x}^{3}, {y}^{3}) ...,({x}^{n}, {y}^{n}) $ \n",
    "\n",
    "![scatter_plot_iris](../images/qqplot.jpeg)\n",
    "\n",
    "* If all points lie on a straight line then the random variable $X$ and random variable $Y$ have similar distributions. \n",
    "\n",
    "### How distributions are used\n",
    "\n",
    "* Gaussian distribution can be used to detect outliers\n",
    "* Proabability distributions are like data structures in Comp Science. \n",
    "* Proabability distributions describe the way we think of outcomes in our daily activities, ex roll of dice, arrival of bus, delays in airlines, etc. \n",
    "* Instead of blind guessing distribution based approach is more trustworthy\n",
    "\n",
    "\n",
    "### Chebyshev's Inequality\n",
    "\n",
    "* If random variable $X$ has finte variance ($\\sigma^2$) and non zero mean ($\\mu$) then $k\\sigma \\le (X-\\mu) \\le k\\sigma$, k - standard deviations away.\n",
    " \n",
    "$$P(| X - \\sigma  |) \\le \\frac {1} {K} $$\n",
    "or \n",
    "$$P(\\mu - k\\sigma < X < \\mu + k\\sigma ) > 1- \\frac {1} {K^2} $$\n",
    "\n",
    "* Without knowing anything about the underlying distribution of random variable $X$, Chebyshev's inequality tells us that we can be at least 90% sure about future events will be within three or (k) standard deviations away from the mean. \n",
    "\n",
    "\n",
    "### Uniform Distribution\n",
    "\n",
    "A random variable $X$ is said to have uniform distribution if all outcomes have same probabilities. There are two types of UD, discrete and continous. UD have zero skew.\n",
    "\n",
    "\n",
    "* Discrete Uniform Distribution\n",
    "    - Roll of dice \n",
    "    - \n",
    "![scatter_plot_iris](../images/udd.png)\n",
    "\n",
    "* Continous Uniform Distribution \n",
    "    - Elevator in a building coming up or going with uniform speed\n",
    "![scatter_plot_iris](../images/ucd.png)\n",
    "\n",
    "### Bernoulli Distribution\n",
    "\n",
    "* When you have two outcome p and 1-p.,zero or one, coinf flip\n",
    "* Could represent outcomes that arent equally likely ex unfair coin. \n",
    "![scatter_plot_iris](../images/bernoulli.png)\n",
    "\n",
    "### Binomial Distribution\n",
    "\n",
    "* Bernoulli distribution is a special case of binomial distribution. Specifically, when n=1 the binomial distribution becomes Bernoulli distribution.\n",
    "* A binomial distribution is the sum of independent and identically distributed Bernoulli random variables or repeated bernoulli trial leads to binomial distribution\n",
    "![scatter_plot_iris](../images/binomial.jpeg)\n",
    "\n",
    "\n",
    "### Log Normal Distribution\n",
    "\n",
    "* Most commonly see in internet companies, comments to a post, income of people, charecterized by heavy tails, most observations are small but with fat chunks, takes on values whose logarithm is normally distributed\n",
    "![scatter_plot_iris](../images/lognormaldistribution.png)\n",
    "\n",
    "### Power law, Pareto Distribution\n",
    "\n",
    "* 80/20 rule\n",
    "* few large values lots of small values \n",
    "* log-log plot is used to determine if a distribution is pareto or not\n",
    "* If a distribution follows power law then its called pareto distribution\n",
    "\n",
    "![scatter_plot_iris](../images/pareto.png)\n",
    "\n",
    "### Weibull Distribution\n",
    "\n",
    "* Can model increasing or decreasing rates of failure over time, time-to-failure\n",
    "![scatter_plot_iris](../images/bathtub_curve.png)\n",
    "\n",
    "### Comparing two random variables \n",
    "\n",
    "* Describe the relationship between two random variables, there are three measures \n",
    "    * Covariance \n",
    "    * Peason Correlation\n",
    "    * Spearman Rank or Correlation Coefficiant\n",
    "\n",
    "### Covariance\n",
    "\n",
    "* Covariance is a measure of the joint variability of two random variables.\n",
    "* Variance of one random variable $VAR(X) = \\frac {1} {n} \\sum_{i=0}^n (x_i - \\mu_x) $\n",
    "\n",
    "* CoVariance, variance of two random variables $COV(X,Y) = \\frac {1} {n} \\sum_{i=0}^n (x_i - \\mu_x) (y_i - \\mu_y) $ \n",
    "\n",
    "* $COV(X,X) = VAR(X) $\n",
    "\n",
    "* $$ \n",
    "COV(X,Y)=\n",
    "\\begin{cases}\n",
    "\\text{+} &X\\ \\ inc \\  \\  and \\ \\ Y \\ \\ is\\ \\ inc \\\\\n",
    "\\text{-} &X\\ \\ dec \\  \\ and \\ \\ Y \\ \\ is \\ \\ dec \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "![scatter_plot_iris](../images/cov.png)\n",
    "\n",
    "### Pearson Correlation\n",
    "\n",
    "* A Pearson correlation is a number between -1 and 1 that indicates the extent to which two variables are linearly related. The Pearson correlation is also known as the “product moment correlation coefficient” (PMCC) or simply “correlation\n",
    "\n",
    "* Complex relationships not captured, only linear relationship\n",
    "* slope of the line doesnt effect P\n",
    "* \n",
    "* $P(X,Y) = \\frac {COV(X,Y)} {\\sigma_x*\\sigma_y}$ \n",
    "\n",
    "* $-1 \\le P(X,Y) \\le 1$\n",
    "\n",
    "\n",
    "![scatter_plot_iris](../images/pearson.png)\n",
    "\n",
    "### Spearman Ranking \n",
    "\n",
    "* Sort the features and find the rank of each observation.\n",
    "* Compute pearson correlation between the ranks \n",
    "\n",
    "$$\n",
    "\\begin{array}{c|lcr}\n",
    "observation & \\text{Height(X)} & \\text{weight (Y)} & \\text{X_rank} &\\text{Y_rank} \\\\\n",
    "\\hline\n",
    "1 & 160 & 52 & 4 & 3 \\\\\n",
    "2 & 150 & 66 & 2 & 4 \\\\\n",
    "3 & 170 & 68 & 5 & 5 \\\\\n",
    "4 & 140 & 46 & 1 & 1 \\\\\n",
    "5 & 158 & 51 & 3 & 2 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "### Correlation vs Causation\n",
    "\n",
    "* correlation doesnt imply causation\n",
    "* causal models what causes the model\n",
    "* Comman use cases\n",
    "    * Is salary correlated to sq footage of home\n",
    "    * dosage of medicine vs reduction of blood sugar\n",
    "    * Is education correlated with income\n",
    "\n",
    "### Confidence Intervals\n",
    "\n",
    "\n",
    "CI gives us probability percentage range instead of point estimate value. For example $X \\in [a, b]$ with 95% probability. \n",
    "\n",
    "**Computing CI for normal distribution**\n",
    "\n",
    "Question: Assume heights of people follow Gaussian distribution with $\\sigma=168$ and $\\mu=5cm$ what is 95% CI?\n",
    "\n",
    "Solution: For a ND, 95% data lies within $(\\mu \\pm 2\\sigma)$, so heights of people lie within [158,178] with 95% probability \n",
    "\n",
    "**Computing CI for any distribution**\n",
    "\n",
    "Let $X$ be a random variable and sample of $X$ is ${x_1, x_2,...x_{10}}$ with size 10. (let $X$ be heights of people)\n",
    "\n",
    "\n",
    "Case-1: We know the mean or population standard deviation but we dont know the distribution. \n",
    "\n",
    "Assume someone gave us $\\mu=5cm$, using Central limit theorem, sample mean is \n",
    "\n",
    "$$ \\bar{X} = \\frac{\\sum_{i=1}^{10}x_i}{10} $$\n",
    "\n",
    "Sample mean follows gaussian distribution, $\\bar{X} \\sim N(\\mu, \\frac {\\sigma} {\\sqrt N}) $ and $\\mu$ can be calucalated as follows \n",
    "\n",
    "$\\mu \\in [\\bar{X} \\pm \\frac {2\\sigma} {N}] $ with 95 % CI\n",
    "\n",
    "$\\mu \\in (165.34, 171,2)$ \n",
    "\n",
    "\n",
    "Case-2: We dont know the $\\mu$ or population standard deviation\n",
    "\n",
    "For this case we t-distribution or student t-distribution. $\\bar{X} \\sim t(n-1)$, $(n-1)$ is called degrees of freedom. \n",
    "\n",
    "\n",
    "###  Confidence Intervals using Bootstrap\n",
    "\n",
    "**Empirical Bootstrap**\n",
    "\n",
    "\n",
    "Assume we are given the data points $ X:x_1,...., x_n$ and we dont know the underlying distribution.  \n",
    "\n",
    "Step1: Choose $m$ samples from $X$ such that $m <n$, let $S_1 : \\{ x^{1}_1, x^{1}_1,...., x^{1}_m \\}$\n",
    "\n",
    "Step2: Choose $m$ sample with replacement from $X$, let $S_2 : \\{ x^1, x^2,...., x^m \\}$, \n",
    "\n",
    "\n",
    "Keep repeating this until $k$ times, $S_1, S_2,...S_k$ are called bootstrap samples, if you want to calculate 95% CI for median then calculate medians of samples $S_1, S_2,...S_k$. Let the calculated medians $M : \\{m_1, m_2,...,m_k\\}$ \n",
    "\n",
    "Step3: Sort the medians in asc order in set $M$, $ m^{1}_1 \\le m^{1}_2,.... \\le m^{1}_k$, CI for 95% median is $[ m^{1}_{25}, m^{1}_{75}]$ if k=100\n",
    "\n",
    "Repeat the same process for calculating variance and standard deviation.\n",
    "\n",
    "\n",
    "### Hypothesis Testing \n",
    "\n",
    "\n",
    "Question: Is there a difference in heights of students in two classes C1, C2. \n",
    "\n",
    "If the mean of the two classes are very close how to chose which is correct?\n",
    "\n",
    "Approach 1: Choose a test statistic, $\\mu_2 - \\mu_1$\n",
    "\n",
    "Approach 2: Null Hypothesis $H_o$, proof by contradiction. You make an assumption come up with an alternative hypothesis $H_1$, then assume $H_o$ is true then prove it wrong. \n",
    "\n",
    "Approach 3: P-Value, probability of observing $\\mu_2 - \\mu_1$ if my null hypothesis is true. If p-value is high then accept $H_o$, if p-value is low reject then reject $H_o$\n",
    "\n",
    "**Hypothesis testing coing toss**\n",
    "\n",
    "Given a coin, is the coing biased towards heads or not?\n",
    "\n",
    "For a head biased coin$P(H) \\ge 0.5$, if the coing is not biased the $P(H)=0.5$\n",
    "\n",
    "Design the experiment\n",
    "\n",
    "Flip the coin five times count number of heads, let number of heads be random variable $X$.\n",
    "\n",
    "Perform the experiment\n",
    "\n",
    "let the following be \n",
    "\n",
    "Flip1 outcome head\n",
    "\n",
    "Flip2 outcome head\n",
    "\n",
    "Flip3 outcome head\n",
    "\n",
    "Flip4 outcome head\n",
    "\n",
    "Flip5 outcome head\n",
    "\n",
    "$P(X=5 | H_o )$, $H_o$ is the assumptions that coin  is not biased  towards head (null hypothesis)\n",
    "\n",
    "$P(H_o)=0.5$\n",
    "\n",
    "$P(X=5|H_o)= \\frac {1} {2^5} $\n",
    "\n",
    "\n",
    "$P(X=5|H_o) \\sim 3\\% $ \n",
    "\n",
    "there is less than 3% chance of getting five heads in five flips if the coin is not biased. \n",
    "\n",
    "### How to calculate P-Value\n",
    "\n",
    "lets say you have two classes C1 and C2 and let $\\delta = \\mu_2 -\\mu1$, mix them up and repeat the following k-times\n",
    "\n",
    "* Draw 50 items from mix, call it X and remaining 50 items call it Y\n",
    "* Calculate the $\\mu$ of X and Y\n",
    "* Let $\\mu_2 -\\mu_1 = \\alpha_{i}$\n",
    "\n",
    "\n",
    "![scatter_plot_iris](../images/ptest.png)\n",
    "\n",
    "\n",
    "* Sort all the $\\alpha_{i's}$,  check where does $\\delta$ fit in the sorted $\\alpha_{i's}$. The x in the figure below is p-value \n",
    "\n",
    "![scatter_plot_iris](../images/pvalue2.png)\n",
    "\n",
    "### Kolmogorov Smirnov (KS) Test\n",
    "\n",
    "Given two distributions, $X_1$ and $X_2$ are they coming from the same distribution?\n",
    "\n",
    "Step-1: Plot CDF of $X_1$ and $X_2$\n",
    "\n",
    "Step-2: let hypothesis $H_o$ be that they have same distribution\n",
    "\n",
    "Step-3: Test statistic, at any point x, how seperated the CDF's are, $D_{(x,y)}= MAX(CDF(X)-CDF(Y))$\n",
    "\n",
    "Step-4: KS-Test result, $D_{(x,y)} > C\\alpha \\sqrt \\frac {n+m} {m}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
